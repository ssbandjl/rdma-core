git config --global user.email "ssbandjl@163.com"
git config --global user.name "bin"

s:
rdma link add rxe_ens3 type rxe netdev ens3

c:
rdma link add rxe_enp0s31f6 type rxe netdev enp0s31f6


set(CMAKE_BUILD_TYPE DEBUG)


git pull --rebase origin master




libibverbs/examples/rc_pingpong.c -> main
    ...
    dev_list = ibv_get_device_list(NULL)
        struct ibv_device **l = NULL
        num_devices = ibverbs_get_device_list(&device_list)
            LIST_HEAD(sysfs_list)
            ret = find_sysfs_devs_nl(&sysfs_list)
                rdmanl_get_devices(nl, find_sysfs_devs_nl_cb, tmp_sysfs_dev_list)
                    nl_send_simple(nl, RDMA_NL_GET_TYPE(RDMA_NL_NLDEV, RDMA_NLDEV_CMD_GET), -> netlink to kernel
            or ret = find_sysfs_devs(&sysfs_list) -> when use netlink get device failed
            list_for_each_safe(device_list, vdev, tmp, entry)
                list_for_each(&sysfs_list, sysfs_dev, entry)
                    if (same_sysfs_dev(vdev->sysfs, sysfs_dev))
                        old_sysfs = sysfs_dev
                    list_del(&old_sysfs->entry)
            try_all_drivers(&sysfs_list, device_list, &num_devices)
                struct verbs_device *vdev
                list_for_each_safe(sysfs_list, sysfs_dev, tmp, entry) 
                    vdev = try_drivers(sysfs_dev)
                        list_for_each (&driver_list, driver, entry)
                            if (match_driver_id(driver->ops, sysfs_dev))
                                try_driver -> 需要先加载驱动
                                    match_device(ops, sysfs_dev)
                                    vdev = ops->alloc_device(sysfs_dev) -> static struct verbs_device *mlx5_device_alloc
                                        dev = calloc(1, sizeof *dev)
                                        mlx5_set_dv_ctx_ops(&mlx5_dv_ctx_ops)
                                        return &dev->verbs_dev
                                    dev->node_type = sysfs_dev->node_type
                                    dev->transport_type = IBV_TRANSPORT_IB;
                                    strcpy(dev->dev_name,   sysfs_dev->sysfs_name)
                                    strcpy(dev->ibdev_path, sysfs_dev->ibdev_path)
                    list_add(device_list, &vdev->entry)
                    (*num_devices)++;
            load_drivers() -> 第一次需要加载驱动才能匹配设备
                list_for_each_safe (&driver_name_list, name, next_name, entry)
                    load_driver(name->name)
            drivers_loaded = 1
            try_all_drivers(&sysfs_list, device_list, &num_devices)
        l = calloc(num_devices + 1, sizeof (struct ibv_device *))
        list_for_each(&device_list, device, entry)
            l[i] = &device->device;
        return l    
    ctx = pp_init_ctx(ib_dev, size, rx_depth, ib_port, use_event)
        ...
        ctx->context = ibv_open_device(ib_dev) -> verbs_open_device
            cmd_fd = open_cdev -> /dev/infiniband/uverbs0 <- #define RDMA_CDEV_DIR "/dev/infiniband"
                open_cdev_internal
            context_ex = verbs_device->ops->alloc_context(device, cmd_fd, private_data) -> irdma_ualloc_context
        if (use_event) -> no
            ctx->channel = ibv_create_comp_channel(ctx->context)
        ctx->pd = ibv_alloc_pd(ctx->context) -> IB_USER_VERBS_CMD_ALLOC_PD
        ctx->mr = use_dm ? ibv_reg_dm_mr(ctx->pd, ctx->dm, 0, size, access_flags) : ibv_reg_mr(ctx->pd, ctx->buf, size, access_flags) -> ibv_reg_mr-> ibv_reg_mr_iova2
            mr = get_ops(pd->context)->reg_mr(pd, addr, length, iova, access) -> irdma_ureg_mr
                cmd.reg_type = IRDMA_MEMREG_TYPE_MEM
                ibv_cmd_reg_mr(pd, addr, length,
                    execute_cmd_write(pd->context, IB_USER_VERBS_CMD_REG_MR, cmd,
        ctx->cq_s.cq = ibv_create_cq(ctx->context, rx_depth + 1, NULL, ctx->channel, 0)
        ctx->qp = ibv_create_qp(ctx->pd, &init_attr)
        ibv_query_qp(ctx->qp, &attr, IBV_QP_CAP, &init_attr)
        if (ibv_modify_qp(ctx->qp, &attr, IBV_QP_STATE | IBV_QP_PKEY_INDEX | IBV_QP_PORT | IBV_QP_ACCESS_FLAGS))
        routs = pp_post_recv(ctx, ctx->rx_depth)
        if (ibv_post_recv(ctx->qp, &wr, &bad_wr))
        if (pp_get_port_info(ctx->context, ib_port, &ctx->portinfo))
            ibv_query_port(context, port, attr)
        if (servername) -> client
            rem_dest = pp_client_exch_dest(servername, port, &my_dest)
                socket, connect
                gid_to_wire_gid(&my_dest->gid, gid)
                wire_gid_to_gid(gid, &rem_dest->gid)
        server -> rem_dest = pp_server_exch_dest(ctx, ib_port, mtu, port, sl, &my_dest, gidx)
            socket, bind, listen, accept
            wire_gid_to_gid(gid, &rem_dest->gid)

        










root@xt:~/project/rdma/rdma-core# ls  /dev/infiniband/
issm0  issm1  rdma_cm  umad0  umad1  uverbs0  uverbs1


struct ibv_device {
    enum ibv_node_type	node_type;
    enum ibv_transport_type	transport_type;   -> dev->transport_type = IBV_TRANSPORT_IB
    char			dev_name[IBV_SYSFS_NAME_MAX]; -> ib_register_device(&xtdev->ibdev, "xtrdma_%d", xtdev->rf->hw.device)
}


struct verbs_device {
	struct ibv_device device; /* Must be first */
	struct list_node entry;
};

list_add(device_list, &vdev->entry)



ibv_get_device_name(dev_list[i])


find_sysfs_devs_nl_cb
    nlmsg_parse
    if (!tb[RDMA_NLDEV_ATTR_DEV_NAME] || -> enum rdma_nldev_attr
	    !tb[RDMA_NLDEV_ATTR_DEV_NODE_TYPE] ||
	    !tb[RDMA_NLDEV_ATTR_DEV_INDEX] ||
	    !tb[RDMA_NLDEV_ATTR_NODE_GUID] ||
	    !tb[RDMA_NLDEV_ATTR_PORT_INDEX])
    sysfs_dev = calloc(1, sizeof(*sysfs_dev))
    sysfs_dev->ibdev_idx = nla_get_u32(tb[RDMA_NLDEV_ATTR_DEV_INDEX])
    sysfs_dev->num_ports = nla_get_u32(tb[RDMA_NLDEV_ATTR_PORT_INDEX])
    sysfs_dev->node_guid = nla_get_u64(tb[RDMA_NLDEV_ATTR_NODE_GUID])
    sysfs_dev->ibdev_name -> mlx5-0
    sysfs_dev->ibdev_path
    sysfs_dev->node_type -> IBV_NODE_CA
    list_add(sysfs_list, &sysfs_dev->entry)


static struct mlx5_dv_context_ops mlx5_dv_ctx_ops = {
	.query_device = _mlx5dv_query_device,

	.query_qp_lag_port = _mlx5dv_query_qp_lag_port,
	.modify_qp_lag_port = _mlx5dv_modify_qp_lag_port,

	.modify_qp_udp_sport = _mlx5dv_modify_qp_udp_sport,

	.sched_node_create = _mlx5dv_sched_node_create,
	.sched_leaf_create = _mlx5dv_sched_leaf_create,
	.sched_node_modify = _mlx5dv_sched_node_modify,
	.sched_leaf_modify = _mlx5dv_sched_leaf_modify,
	.sched_node_destroy = _mlx5dv_sched_node_destroy,
	.sched_leaf_destroy = _mlx5dv_sched_leaf_destroy,
	.modify_qp_sched_elem = _mlx5dv_modify_qp_sched_elem,

	.reserved_qpn_alloc = _mlx5dv_reserved_qpn_alloc,
	.reserved_qpn_dealloc = _mlx5dv_reserved_qpn_dealloc,

	.set_context_attr = _mlx5dv_set_context_attr,
	.get_clock_info = _mlx5dv_get_clock_info,
	.init_obj = _mlx5dv_init_obj,
};


libibverbs/verbs.h
libibverbs/verbs.c
/**
 * ibv_alloc_pd - Allocate a protection domain
 */
struct ibv_pd *ibv_alloc_pd(struct ibv_context *context);
    pd = get_ops(context)->alloc_pd(context) -> struct ibv_pd *mlx5_alloc_pd(struct ibv_context *context) | struct ibv_pd *irdma_ualloc_pd(struct ibv_context *context)



static const struct verbs_context_ops irdma_uctx_ops = {
	.alloc_mw = irdma_ualloc_mw,
	.alloc_pd = irdma_ualloc_pd,
	.attach_mcast = irdma_uattach_mcast,
	.bind_mw = irdma_ubind_mw,
	.cq_event = irdma_cq_event,
	.create_ah = irdma_ucreate_ah,
	.create_cq = irdma_ucreate_cq,
	.create_cq_ex = irdma_ucreate_cq_ex,
	.create_qp = irdma_ucreate_qp,
	.dealloc_mw = irdma_udealloc_mw,
	.dealloc_pd = irdma_ufree_pd,
	.dereg_mr = irdma_udereg_mr,
	.destroy_ah = irdma_udestroy_ah,
	.destroy_cq = irdma_udestroy_cq,
	.destroy_qp = irdma_udestroy_qp,
	.detach_mcast = irdma_udetach_mcast,
	.modify_qp = irdma_umodify_qp,
	.poll_cq = irdma_upoll_cq,
	.post_recv = irdma_upost_recv,
	.post_send = irdma_upost_send,
	.query_device_ex = irdma_uquery_device_ex,
	.query_port = irdma_uquery_port,
	.query_qp = irdma_uquery_qp,
	.reg_dmabuf_mr = irdma_ureg_mr_dmabuf,
	.reg_mr = irdma_ureg_mr,
	.req_notify_cq = irdma_uarm_cq,
	.resize_cq = irdma_uresize_cq,
	.free_context = irdma_ufree_context,
};


struct ibv_pd *irdma_ualloc_pd(struct ibv_context *context)
    ibv_cmd_alloc_pd(context, &iwupd->ibv_pd, &cmd, sizeof(cmd),



struct ibv_mem_node {
	enum {
		IBV_RED,
		IBV_BLACK
	}			color;
	struct ibv_mem_node    *parent;
	struct ibv_mem_node    *left, *right;
	uintptr_t		start, end;
	int			refcnt;
};
static struct ibv_mem_node *mm_root;

struct ibv_mr *ibv_reg_mr_iova2(struct ibv_pd *pd, void *addr, size_t length, uint64_t iova, unsigned int access)
    bool odp_mr = access & IBV_ACCESS_ON_DEMAND
    if (!odp_mr && ibv_dontfork_range(addr, length))
        if (mm_root)
            ibv_madvise_range(base, size, MADV_DONTFORK)
        else
            too_late = 1
    mr = get_ops(pd->context)->reg_mr(pd, addr, length, iova, access)





static int ibv_madvise_range
    static struct ibv_mem_node *split_range
        static void __mm_add(struct ibv_mem_node *new)
            __mm_add_rebalance
                ...
                gp->color     = IBV_RED;

                